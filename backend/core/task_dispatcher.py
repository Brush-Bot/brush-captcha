import asyncio
import time

from core.task_manager import task_pool,Status
from core.worker_manager import worker_pool
from common.logger import get_logger,emoji
from proxy.proxy_manager import ProxyManager
logger = get_logger("task_dispatcher")
proxy_mgr = ProxyManager()
# ä»¥ä»»åŠ¡å¾ªç¯ï¼Œé€‚åˆå°‘é‡æœºå™¨ï¼Œä¿è¯æœ€ä¼˜ç©ºé—²è°ƒåº¦
async def dispatch_tasks_by_tasks():
    for task in task_pool.values():
        if task["status"] != Status.WAITING:
            continue
        # æ‰¾å‡ºæ”¯æŒä»»åŠ¡ç±»å‹ã€ä¸”æœªæ»¡è½½çš„ worker
        candidates = [
            (wid, w) for wid, w in worker_pool.items()
            if task["type"] in w["task_types"]
            and w["current_tasks"] < w["max_concurrency"]
        ]

        if not candidates:
            continue  # æš‚æ— å¯æ¥æ­¤ä»»åŠ¡çš„ worker

        # è®¡ç®—ç©ºé—²æ•°å¹¶æŒ‰ç©ºé—²æ•°é™åºæ’åºï¼ˆç©ºé—²å¤šçš„æ’å‰ï¼‰
        candidates.sort(key=lambda x: x[1]["max_concurrency"] - x[1]["current_tasks"], reverse=True)

        worker_id, worker = candidates[0]

        try:
            proxy_config = proxy_mgr.assign_proxy()
            if proxy_config:
                logger.debug(f"proxy config: {proxy_config}")
            else:
                logger.error(emoji("ERROR","æ²¡æœ‰å¯ç”¨ä»£ç†,ç­‰å¾…1åˆ†é’Ÿå†å¼€å§‹åˆ†é…"))
                await asyncio.sleep(60)
                continue
            await worker["ws"].send_json({
                "type": "new_task",
                "proxy": proxy_config,
                "task": {
                    "taskId": task["taskId"],
                    **task["payload"]
                }
            })
            task["status"] = Status.PENDING
            task["assignedTo"] = worker_id
            worker["current_tasks"] += 1
            logger.info(f"ğŸ“¤ åˆ†å‘ä»»åŠ¡ {task['taskId']} â†’ {worker_id}")
        except Exception as e:
            logger.info(f"âŒ å‘é€å¤±è´¥ {worker_id}: {e}")
            continue
# ä»¥workerå¾ªç¯ï¼Œé€‚åˆå¤§é‡worker
# æŒ‰å½“å‰è´Ÿè½½æ¯”ä¾‹æ’åºï¼Œä¼˜å…ˆåˆ†å‘ç»™æ›´ç©ºé—²çš„ worker
async def dispatch_tasks_by_worker():
    sorted_workers = sorted(
        worker_pool.items(),
        key=lambda x: (x[1]["current_tasks"] / x[1]["max_concurrency"]) if x[1]["max_concurrency"] > 0 else 1.0
    )

    for worker_id, worker in sorted_workers:
        available_slots = worker["max_concurrency"] - worker["current_tasks"]
        if available_slots <= 0:
            continue

        for task in task_pool.values():
            if task["status"] != Status.WAITING:
                continue
            if task["type"] not in worker["task_types"]:
                continue

            try:
                proxy_config = proxy_mgr.assign_proxy()
                if proxy_config:
                    logger.debug(f"proxy config: {proxy_config}")
                else:
                    logger.error(emoji("ERROR", "æ²¡æœ‰å¯ç”¨ä»£ç†,ç­‰å¾…1åˆ†é’Ÿå†å¼€å§‹åˆ†é…"))
                    await asyncio.sleep(60)
                    continue
                await worker["ws"].send_json({
                    "type": "new_task",
                    "proxy": proxy_config,
                    "task": {
                        "taskId": task["taskId"],
                        **task["payload"]
                    }
                })
                task["status"] = Status.PENDING
                task["assignedTo"] = worker_id
                worker["current_tasks"] += 1
                logger.info(f"ğŸ“¤ åˆ†å‘ä»»åŠ¡ {task['taskId']} â†’ {worker_id}")
                break  # åªåˆ†ä¸€ä¸ªä»»åŠ¡ç»™è¿™ä¸ª worker
            except Exception as e:
                logger.warning(f"âŒ åˆ†å‘ä»»åŠ¡ {task['taskId']} åˆ° {worker_id} å¤±è´¥: {e}")
                continue
# ä¸»å¾ªç¯
async def scheduler_loop():
    while True:
        try:
            await dispatch_tasks_by_worker()
        except Exception as e:
            logger.error(f"âŒ è°ƒåº¦å™¨å¼‚å¸¸ï¼š{e}")
        await asyncio.sleep(0.3) # åˆ†å‘é¢‘ç‡